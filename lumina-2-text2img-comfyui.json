{
  "id": "b72481a4-e3ef-4d7d-adaf-9664d4931ac0",
  "revision": 0,
  "last_node_id": 16,
  "last_link_id": 20,
  "nodes": [
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1209,
        188
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "label": "samples",
          "name": "samples",
          "type": "LATENT",
          "link": 14
        },
        {
          "label": "vae",
          "name": "vae",
          "type": "VAE",
          "link": 8
        }
      ],
      "outputs": [
        {
          "label": "IMAGE",
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            16
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 13,
      "type": "EmptySD3LatentImage",
      "pos": [
        530,
        620
      ],
      "size": [
        315,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "label": "LATENT",
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            17
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        420,
        400
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "label": "clip",
          "name": "clip",
          "type": "CLIP",
          "link": 5
        }
      ],
      "outputs": [
        {
          "label": "CONDITIONING",
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            6
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "blurry ugly bad"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1515.7877197265625,
        39.72430419921875
      ],
      "size": [
        976.0567626953125,
        1060.9766845703125
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "label": "images",
          "name": "images",
          "type": "IMAGE",
          "link": 16
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 15,
      "type": "Note",
      "pos": [
        13.676860809326172,
        212.60264587402344
      ],
      "size": [
        319.26513671875,
        197.89625549316406
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "The \"You are an assistant... <Prompt Start> \" text before the actual prompt is the one used in the official example.\n\nThe reason it is exposed to the user like this is because the model still works if you modify or remove it."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 14,
      "type": "Note",
      "pos": [
        860,
        -50
      ],
      "size": [
        310,
        180
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "The official way to sample this model is: shift 6 with 36 steps\n\nSampling it with lower steps works but you might have to lower the shift value to reduce the amount of artifacts.\n\nEx: 20 steps with shift 3 seems to not produce artifacts"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 11,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        520.5050048828125,
        84.46595764160156
      ],
      "size": [
        315,
        58
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "label": "model",
          "name": "model",
          "type": "MODEL",
          "link": 20
        }
      ],
      "outputs": [
        {
          "label": "MODEL",
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            13
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "ModelSamplingAuraFlow"
      },
      "widgets_values": [
        6
      ]
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        -101.6262435913086,
        518.7349853515625
      ],
      "size": [
        315,
        98
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "label": "MODEL",
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            20
          ]
        },
        {
          "label": "CLIP",
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 1,
          "links": [
            3,
            5
          ]
        },
        {
          "label": "VAE",
          "name": "VAE",
          "type": "VAE",
          "slot_index": 2,
          "links": [
            8
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "neta-lumina-beta-0624-all-in-one.safetensors"
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        863,
        186
      ],
      "size": [
        315,
        474
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "label": "model",
          "name": "model",
          "type": "MODEL",
          "link": 13
        },
        {
          "label": "positive",
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "label": "negative",
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "label": "latent_image",
          "name": "latent_image",
          "type": "LATENT",
          "link": 17
        }
      ],
      "outputs": [
        {
          "label": "LATENT",
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            14
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        340827798768369,
        "randomize",
        25,
        4,
        "res_multistep",
        "simple",
        1
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        420,
        190
      ],
      "size": [
        423.83001708984375,
        177.11770629882812
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "label": "clip",
          "name": "clip",
          "type": "CLIP",
          "link": 3
        }
      ],
      "outputs": [
        {
          "label": "CONDITIONING",
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            4
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "You are an assistant designed to generate anime images based on textual prompts. <Prompt Start> \nportgas d. ace, @quasarcake, @nixeu, 1boy, solo, male focus, topless male,\nblack hair, black eyes, happy, freckles, hat, abs, arm tattoo, beads,\ncowboy hat, necklace, orange hat, smile, looking at viewer, upper body,\nfrom side, depth of field, sunlight, warm colors, blue sky, best quality"
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [
      3,
      4,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      5,
      4,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      8,
      4,
      2,
      8,
      1,
      "VAE"
    ],
    [
      13,
      11,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      14,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      16,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      17,
      13,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      20,
      4,
      0,
      11,
      0,
      "MODEL"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7109141989217256,
      "offset": [
        49.28822806063534,
        29.614575902439014
      ]
    },
    "frontendVersion": "1.22.2",
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}